{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T12:21:44.472090Z",
     "start_time": "2019-07-24T12:21:43.282991Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import _expds_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "syear='2019'\n",
    "pyear='2018'\n",
    "season='2019_games.html'\n",
    "team_url_csv=\"nhl_urls.csv\"\n",
    "csv_out='nhl_games_'\n",
    "season_start=pyear+'-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_current_season_links (url,team,url_ref):\n",
    "    #url='https://www.baseball-reference.com/teams/ATL/'\n",
    "    #url_ref='2018-schedule-scores.shtml'\n",
    "    page = requests.get(url+url_ref) #downloads html contents of the website and stores them\n",
    "    #page.status_code tells if download was successful. starting with 2 is good, with 4 or 5 means wrong\n",
    "    #can print content with page.content for html\n",
    "    soup = BeautifulSoup(page.text, 'html.parser') #parse HTML content for information in <p> tag\n",
    "\n",
    "    soup_filter=soup.find(\"table\", attrs={'class':'sortable stats_table'}) #find all instances of a certain tag, in this case \"div\"\n",
    "    table_body = soup_filter.find('tbody')\n",
    "    \n",
    "    l = []\n",
    "    #Loop over table rows, collect all table data entries, store row text, add to list\n",
    "    for tr in table_body.find_all('tr',class_='')[0:]:\n",
    "        tds = tr.find_all('td')\n",
    "        row = [tr.text for tr in tds]\n",
    "        l.append(row) \n",
    "        \n",
    "    dfout=pd.DataFrame(l) \n",
    "    \n",
    "    dfout['Team']=team\n",
    "    \n",
    "    return dfout  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds=pd.read_csv(team_url_csv)\n",
    "team_url_list = ds.iloc[:,0].tolist()\n",
    "team_url_list = list(set(team_url_list))\n",
    "team_abrv=[]\n",
    "for i in team_url_list:\n",
    "    team_abrv.append(i[-4:-1])\n",
    "if syear == '2017':\n",
    "    team_abrv.remove('VEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df = pd.DataFrame()\n",
    "for u,w in zip(team_url_list,team_abrv):\n",
    "    #print(u)\n",
    "    #print(w)\n",
    "    dfatl=get_current_season_links(u,w,season) #\n",
    "    games_df=games_df.append(dfatl) #add new dataframe to empty one\n",
    "\n",
    "if syear == '2019':\n",
    "    games_df.columns = ['date_raw', 'home_away', 'opponent','home_score','away_score','result','1','wins','losses','ot_losses','streak','attendance','2','3','home_team_abrv']\n",
    "else: \n",
    "    games_df.columns = ['date_raw', 'time', 'home_away', 'opponent','home_score','away_score','result','1','wins','losses','ot_losses','streak','attendance','2','3','home_team_abrv']\n",
    "games_df.drop(columns=['1','2','3'], inplace = True)\n",
    "\n",
    "games_df['date_raw'].replace('', np.nan, inplace=True)\n",
    "games_df['streak'].replace('', 'N 0', inplace=True)\n",
    "games_df.dropna(subset=['date_raw'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_raw</th>\n",
       "      <th>home_away</th>\n",
       "      <th>opponent</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>result</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>ot_losses</th>\n",
       "      <th>streak</th>\n",
       "      <th>attendance</th>\n",
       "      <th>home_team_abrv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td></td>\n",
       "      <td>Calgary Flames</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>W 1</td>\n",
       "      <td>18,870</td>\n",
       "      <td>VAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-06</td>\n",
       "      <td>@</td>\n",
       "      <td>Calgary Flames</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>L 1</td>\n",
       "      <td>18,688</td>\n",
       "      <td>VAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-10-09</td>\n",
       "      <td>@</td>\n",
       "      <td>Carolina Hurricanes</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>L 2</td>\n",
       "      <td>11,932</td>\n",
       "      <td>VAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>@</td>\n",
       "      <td>Tampa Bay Lightning</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>W</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>W 1</td>\n",
       "      <td>19,092</td>\n",
       "      <td>VAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-10-13</td>\n",
       "      <td>@</td>\n",
       "      <td>Florida Panthers</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>W</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>W 2</td>\n",
       "      <td>11,953</td>\n",
       "      <td>VAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_raw home_away             opponent home_score away_score result  \\\n",
       "0  2018-10-03                 Calgary Flames          5          2      W   \n",
       "1  2018-10-06         @       Calgary Flames          4          7      L   \n",
       "2  2018-10-09         @  Carolina Hurricanes          3          5      L   \n",
       "3  2018-10-11         @  Tampa Bay Lightning          4          1      W   \n",
       "4  2018-10-13         @     Florida Panthers          3          2      W   \n",
       "\n",
       "  wins losses ot_losses streak attendance home_team_abrv  \n",
       "0    1      0         0    W 1     18,870            VAN  \n",
       "1    1      1         0    L 1     18,688            VAN  \n",
       "2    1      2         0    L 2     11,932            VAN  \n",
       "3    2      2         0    W 1     19,092            VAN  \n",
       "4    3      2         0    W 2     11,953            VAN  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Standardize date\n",
    "split_date = games_df['date_raw'].str.split('-',n=3,expand = True)\n",
    "        \n",
    "dates = []\n",
    "day_of_week = []\n",
    "for i in range(0,len(split_date[1])):\n",
    "    day = dt.date(int(split_date[0].iloc[i][-4:]), int(split_date[1].iloc[i]), int(split_date[2].iloc[i]))\n",
    "    time = day.strftime(\"%Y-%m-%d\")\n",
    "    day_of_week.append(day.strftime('%A'))\n",
    "    dates.append(time)\n",
    "games_df['game_date'] = dates\n",
    "games_df['day_of_week'] = day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weekend\n",
    "week_ends = []\n",
    "\n",
    "for i in range(0,len(games_df['day_of_week'])):\n",
    "    if games_df['day_of_week'].iloc[i] == 'Friday':\n",
    "        week_ends.append(1)\n",
    "    elif games_df['day_of_week'].iloc[i] == 'Saturday':\n",
    "        week_ends.append(1)\n",
    "    elif games_df['day_of_week'].iloc[i] == 'Sunday':\n",
    "        week_ends.append(1)\n",
    "    else: week_ends.append(0)\n",
    "        \n",
    "games_df['weekend_flag'] = week_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_game=games_df.groupby('home_team_abrv',as_index=False).first()\n",
    "first_game.head()\n",
    "first_game=first_game[['home_team_abrv','game_date']]\n",
    "\n",
    "first_game_flag = []\n",
    "for index, row in first_game.iterrows():\n",
    "    first_game_flag.append(1)\n",
    "first_game['first_game_flag']=first_game_flag\n",
    "\n",
    "games_df = pd.merge(games_df,first_game,on=['home_team_abrv','game_date'], how='left')\n",
    "games_df['first_game_flag'].replace(np.nan, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#home or away\n",
    "home_or_away = []\n",
    "for index, row in games_df.iterrows():\n",
    "    if row['home_away']=='@': home_or_away.append(0)\n",
    "    else: home_or_away.append(1)\n",
    "    \n",
    "games_df['home_flag'] = home_or_away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Streaks\n",
    "streaks = []\n",
    "i = 0\n",
    "#len(games_df.streak_raw)\n",
    "for i in range(0,len(games_df.streak)):\n",
    "    streaks.append(int(str(games_df.streak.iloc[i])[-1]))\n",
    "    if games_df.streak.iloc[i].find(\"L\") == 0:\n",
    "        streaks[i] = streaks[i] * -1\n",
    "    else:\n",
    "        streaks[i] = streaks[i]\n",
    "games_df['streak'] = streaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Join in group_id\n",
    "games_df_merge = pd.merge(games_df, ds,  how='left', left_on=['home_team_abrv'], right_on = ['team_abbreviation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_raw</th>\n",
       "      <th>home_away</th>\n",
       "      <th>opponent</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "      <th>result</th>\n",
       "      <th>wins</th>\n",
       "      <th>losses</th>\n",
       "      <th>ot_losses</th>\n",
       "      <th>streak</th>\n",
       "      <th>...</th>\n",
       "      <th>group_id</th>\n",
       "      <th>city</th>\n",
       "      <th>zip_code_us</th>\n",
       "      <th>group_config_id</th>\n",
       "      <th>group_type_id</th>\n",
       "      <th>short_name</th>\n",
       "      <th>alert_name</th>\n",
       "      <th>billing_category_id</th>\n",
       "      <th>home_demand_tier</th>\n",
       "      <th>away_demand_tier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-03</td>\n",
       "      <td></td>\n",
       "      <td>Calgary Flames</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>W</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>309.0</td>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>VANC</td>\n",
       "      <td>Canucks Alert</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-06</td>\n",
       "      <td>@</td>\n",
       "      <td>Calgary Flames</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>309.0</td>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>VANC</td>\n",
       "      <td>Canucks Alert</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-10-09</td>\n",
       "      <td>@</td>\n",
       "      <td>Carolina Hurricanes</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>L</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>309.0</td>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>VANC</td>\n",
       "      <td>Canucks Alert</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>@</td>\n",
       "      <td>Tampa Bay Lightning</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>W</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>309.0</td>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>VANC</td>\n",
       "      <td>Canucks Alert</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-10-13</td>\n",
       "      <td>@</td>\n",
       "      <td>Florida Panthers</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>W</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>309.0</td>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>VANC</td>\n",
       "      <td>Canucks Alert</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_raw home_away             opponent home_score away_score result  \\\n",
       "0  2018-10-03                 Calgary Flames          5          2      W   \n",
       "1  2018-10-06         @       Calgary Flames          4          7      L   \n",
       "2  2018-10-09         @  Carolina Hurricanes          3          5      L   \n",
       "3  2018-10-11         @  Tampa Bay Lightning          4          1      W   \n",
       "4  2018-10-13         @     Florida Panthers          3          2      W   \n",
       "\n",
       "  wins losses ot_losses  streak  ... group_id           city zip_code_us  \\\n",
       "0    1      0         0       1  ...    309.0  Vancouver, BC         NaN   \n",
       "1    1      1         0      -1  ...    309.0  Vancouver, BC         NaN   \n",
       "2    1      2         0      -2  ...    309.0  Vancouver, BC         NaN   \n",
       "3    2      2         0       1  ...    309.0  Vancouver, BC         NaN   \n",
       "4    3      2         0       2  ...    309.0  Vancouver, BC         NaN   \n",
       "\n",
       "  group_config_id  group_type_id  short_name     alert_name  \\\n",
       "0           170.0            9.0        VANC  Canucks Alert   \n",
       "1           170.0            9.0        VANC  Canucks Alert   \n",
       "2           170.0            9.0        VANC  Canucks Alert   \n",
       "3           170.0            9.0        VANC  Canucks Alert   \n",
       "4           170.0            9.0        VANC  Canucks Alert   \n",
       "\n",
       "  billing_category_id home_demand_tier away_demand_tier  \n",
       "0                 6.0                2                2  \n",
       "1                 6.0                2                2  \n",
       "2                 6.0                2                2  \n",
       "3                 6.0                2                2  \n",
       "4                 6.0                2                2  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games_df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path \n",
    "\n",
    "env_path = Path('.') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "postgres_user = os.environ['PSQL_USERNAME']\n",
    "postgres_pw = os.environ['PSQL_PASSWORD']\n",
    "postgres_url = os.environ['PSQL_URL']\n",
    "\n",
    "redshift_user = os.environ['REDSHIFT_USERNAME']\n",
    "redshift_pw = os.environ['REDSHIFT_PASSWORD']\n",
    "redshift_url = os.environ['REDSHIFT_URL']\n",
    "\n",
    "t_consumer_key = os.environ['TWT_CONSUMER_KEY']\n",
    "t_consumer_secret = os.environ['TWT_CONSUMER_SECRET']\n",
    "t_access_token = os.environ['TWT_ACCESS_TOKEN_KEY']\n",
    "t_access_token_secret = os.environ['TWT_ACCESS_TOKEN_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this block makes the connection to postgres db (tableau/follower)\n",
    "conn_string = \"host='\"+postgres_url+\"' dbname='experience' user='\"+postgres_user+\"' password='\"+postgres_pw+\"'\"\n",
    "conn = psycopg2.connect(conn_string)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this block makes the connection to redshift (redluma)\n",
    "red_engine = create_engine('postgresql://'+redshift_user+':'+redshift_pw+'@'+redshift_url)\n",
    "conn_red = red_engine.raw_connection()\n",
    "cur = conn_red.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement=\"\"\"\n",
    "select g.* \n",
    "    ,gr.*\n",
    "    ,TO_CHAR(g.game_start_time - INTERVAL '5 hours','YYYY-MM-DD') AS game_date\n",
    "    ,gr.id as group_id\n",
    "    ,g.id as game_id\n",
    "    ,v.name as venue\n",
    "    ,v.max_attendance \n",
    "  from game g\n",
    "  join \"group\" gr\n",
    "  on g.home_team_id=gr.id and gr.group_type_id=9\n",
    "  left join venue v\n",
    "  on gr.id=v.group_id\n",
    "where g.game_start_time>'{}';\n",
    "\"\"\".format(season_start)\n",
    "games_exp = pd.read_sql(statement, conn)\n",
    "games_exp.to_csv('nhl_games_test_right.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#left join games_df to games_exp on date, game_date group_ip, home_team_id\n",
    "games_df_merge_full = pd.merge(games_df_merge, games_exp,  how='left', on=['group_id','game_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement=\"\"\"\n",
    "select \n",
    " CAST(game_id AS INTEGER) as game_id\n",
    ",group_name\n",
    ",final_event_name\n",
    ",away_team_fix\n",
    ",away_demand_tier as away_demand_tier_tm\n",
    ",home_demand_tier as home_demand_tier_tm\n",
    ",sum(seats_sold) as seats_sold\n",
    ",sum(seats_scanned) as scanned_seats\n",
    ",sum(section_seats) as assumed_capacity\n",
    "\n",
    "from temp_attn_rates\n",
    "where segment='NHL'\n",
    "group by 1,2,3,4,5,6;\n",
    "\"\"\"\n",
    "sales_scan = pd.read_sql(statement, conn_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "games_df_merge_full_sales = pd.merge(games_df_merge_full, sales_scan,  how='left', on=['game_id'])\n",
    "games_df_merge_full_sales.dropna(subset=['group_name'], inplace=True)\n",
    "games_df_merge_full_sales.to_csv('nhl_games_test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_raw                         object\n",
       "home_away                        object\n",
       "opponent                         object\n",
       "home_score                       object\n",
       "away_score                       object\n",
       "result                           object\n",
       "wins                             object\n",
       "losses                           object\n",
       "ot_losses                        object\n",
       "streak                            int64\n",
       "attendance                       object\n",
       "home_team_abrv                   object\n",
       "game_date                        object\n",
       "day_of_week                      object\n",
       "weekend_flag                      int64\n",
       "first_game_flag                 float64\n",
       "home_flag                         int64\n",
       "url                              object\n",
       "team_abbreviation                object\n",
       "team_name_expapp                 object\n",
       "team_name_web                    object\n",
       "group_id                        float64\n",
       "city_x                           object\n",
       "zip_code_us                     float64\n",
       "group_config_id_x               float64\n",
       "group_type_id_x                 float64\n",
       "short_name_x                     object\n",
       "alert_name_x                     object\n",
       "billing_category_id_x           float64\n",
       "home_demand_tier                  int64\n",
       "away_demand_tier                  int64\n",
       "id                              float64\n",
       "active                           object\n",
       "away_team                        object\n",
       "date_created             datetime64[ns]\n",
       "game_config_id                  float64\n",
       "game_start_time          datetime64[ns]\n",
       "home_team_id                    float64\n",
       "last_updated             datetime64[ns]\n",
       "name                             object\n",
       "venue_id                        float64\n",
       "additional_details               object\n",
       "game_imageurl                    object\n",
       "away_team_imageurl               object\n",
       "id                              float64\n",
       "city_y                           object\n",
       "date_created             datetime64[ns]\n",
       "group_config_id_y               float64\n",
       "group_type_id_y                 float64\n",
       "last_updated             datetime64[ns]\n",
       "name                             object\n",
       "short_name_y                     object\n",
       "alert_name_y                     object\n",
       "billing_category_id_y           float64\n",
       "game_id                         float64\n",
       "venue                            object\n",
       "max_attendance                  float64\n",
       "group_name                       object\n",
       "final_event_name                 object\n",
       "away_team_fix                    object\n",
       "away_demand_tier_tm             float64\n",
       "home_demand_tier_tm             float64\n",
       "seats_sold                      float64\n",
       "scanned_seats                   float64\n",
       "assumed_capacity                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "games_df_merge_full_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "game_feature=games_df_merge_full_sales[[\\\n",
    "'result',\\\n",
    "'home_score',\\\n",
    "'away_score',\\\n",
    "'wins',\\\n",
    "'losses',\\\n",
    "'streak',\\\n",
    "'home_team_abrv',\\\n",
    "'game_date',\\\n",
    "'weekend_flag',\\\n",
    "'first_game_flag',\\\n",
    "'day_of_week',\\\n",
    "'group_id',\\\n",
    "'game_id',\\\n",
    "'away_team',\\\n",
    "'name',\\\n",
    "'max_attendance',\\\n",
    "'away_demand_tier',\\\n",
    "'home_demand_tier',\\\n",
    "'seats_sold',\\\n",
    "'scanned_seats',\\\n",
    "'assumed_capacity']]\n",
    "game_feature=game_feature.astype({'wins': 'int32'})\n",
    "game_feature=game_feature.astype({'losses': 'int32'})\n",
    "game_feature=game_feature.astype({'away_demand_tier': 'int32'})\n",
    "game_feature=game_feature.astype({'home_demand_tier': 'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#current win/loss ratio\n",
    "ratios = []\n",
    "for index, row in game_feature.iterrows():\n",
    "    ratios.append(int(row['wins'])/(int(row['wins'])+int(row['losses']))) \n",
    "    \n",
    "game_feature['wl_ratio'] = ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%neg streak days\n",
    "days = []\n",
    "neg_days = []\n",
    "gt_two_pos_days = []\n",
    "for index, row in game_feature.iterrows():\n",
    "    if row['streak']<0 : neg_days.append(1)\n",
    "    else : neg_days.append(0)\n",
    "    if row['streak']>2 : gt_two_pos_days.append(1)\n",
    "    else : gt_two_pos_days.append(0)\n",
    "    days.append(1)\n",
    "    \n",
    "game_feature['neg_streak_days'] = neg_days\n",
    "game_feature['pos_streak_gt_2_days'] = gt_two_pos_days\n",
    "game_feature['days'] = days\n",
    "\n",
    "game_feature['c_neg_streak_days']=game_feature.groupby(['home_team_abrv'])['neg_streak_days'].cumsum()\n",
    "game_feature['c_pos_streak_gt_2_days']=game_feature.groupby(['home_team_abrv'])['pos_streak_gt_2_days'].cumsum()\n",
    "game_feature['c_days']=game_feature.groupby(['home_team_abrv'])['days'].cumsum()\n",
    "\n",
    "game_feature['pct_neg_streak']=game_feature['c_neg_streak_days']/game_feature['c_days']\n",
    "game_feature['pct_pos_streak_gt_2_days']=game_feature['c_pos_streak_gt_2_days']/game_feature['c_days']\n",
    "\n",
    "game_feature['c10_neg_streak_days']=game_feature.groupby('home_team_abrv')['neg_streak_days'].rolling(10).sum().reset_index(0,drop=True)\n",
    "game_feature['c10_pos_streak_gt_2_days']=game_feature.groupby('home_team_abrv')['pos_streak_gt_2_days'].rolling(10).sum().reset_index(0,drop=True)\n",
    "\n",
    "roll_neg_days = []\n",
    "roll_gt_two_pos_days = []\n",
    "for index, row in game_feature.iterrows():\n",
    "    if row['c10_neg_streak_days'] >=0: roll_neg_days.append(row['c10_neg_streak_days']/row['c_days']) \n",
    "    else : roll_neg_days.append(row['pct_neg_streak'])\n",
    "    if row['c10_pos_streak_gt_2_days'] >=0 : roll_gt_two_pos_days.append(row['c10_pos_streak_gt_2_days']/row['c_days'])\n",
    "    else : roll_gt_two_pos_days.append(row['pct_pos_streak_gt_2_days']) \n",
    "\n",
    "game_feature['pct_c10_neg_streak_days'] = roll_neg_days\n",
    "game_feature['pct_c10_pos_streak_gt_2_days'] = roll_gt_two_pos_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#day_of_week_flag(s)\n",
    "dummy=pd.get_dummies(game_feature['day_of_week'])\n",
    "game_feature=pd.concat([game_feature,dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "#home_team_tier x away_team_tier\n",
    "tiers = []\n",
    "for index, row in game_feature.iterrows():\n",
    "    tiers.append('h_'+str(row['home_demand_tier'])+'_a_'+str(row['away_demand_tier']))\n",
    "game_feature['tier_combo'] = tiers\n",
    "\n",
    "dummy=pd.get_dummies(game_feature['tier_combo'])\n",
    "game_feature=pd.concat([game_feature,dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fix GSW arena move\n",
    "#if syear=='2019': \n",
    "#    game_feature.loc[game_feature['home_team_abrv'] == 'GSW', 'assumed_capacity'] = 19500\n",
    "#    game_feature.loc[game_feature['home_team_abrv'] == 'BOS', 'assumed_capacity'] = 18624\n",
    "#Is this block useful for capacity changes in the NHL?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg sell-through\n",
    "#avg scan-through\n",
    "sell_through = []\n",
    "scan_through = []\n",
    "scan_rate = []\n",
    "for index, row in game_feature.iterrows():\n",
    "    sell_through.append(row['seats_sold']/row['assumed_capacity'])\n",
    "    scan_through.append(row['scanned_seats']/row['assumed_capacity'])\n",
    "    scan_rate.append(row['scanned_seats']/row['seats_sold'])\n",
    "    \n",
    "game_feature['sell_through'] = sell_through\n",
    "game_feature['scan_through'] = scan_through\n",
    "game_feature['scan_rate'] = scan_rate\n",
    "\n",
    "game_feature['c_sell_through']=game_feature.groupby(['home_team_abrv'])['sell_through'].cumsum()\n",
    "game_feature['c_scan_through']=game_feature.groupby(['home_team_abrv'])['scan_through'].cumsum()\n",
    "game_feature['c_scan_rate']=game_feature.groupby(['home_team_abrv'])['scan_rate'].cumsum()\n",
    "#need to know avg for the row above though as you don't know that game's rates to add to avg\n",
    "\n",
    "sell_through_avg = []\n",
    "scan_through_avg = []\n",
    "scan_rate_avg = []\n",
    "for index, row in game_feature.iterrows():\n",
    "    sell_through_avg.append(row['c_sell_through']/row['c_days'])\n",
    "    scan_through_avg.append(row['c_scan_through']/row['c_days'])\n",
    "    scan_rate_avg.append(row['c_scan_rate']/row['c_days'])\n",
    "\n",
    "game_feature['c_sell_through_avg'] = sell_through_avg\n",
    "game_feature['c_scan_through_avg'] = scan_through_avg\n",
    "game_feature['c_scan_rate_avg'] = scan_rate_avg    \n",
    "\n",
    "#shift down\n",
    "sell_through_shift = []\n",
    "scan_through_shift = []\n",
    "scan_rate_shift = []\n",
    "\n",
    "sell_through_prev = None\n",
    "scan_through_prev = None\n",
    "scan_rate_prev = None\n",
    "grp = ''\n",
    "for index, row in game_feature.iterrows():\n",
    "    if row['home_team_abrv'] == grp : \n",
    "        sell_through_shift.append(sell_through_prev) \n",
    "        scan_through_shift.append(scan_through_prev) \n",
    "        scan_rate_shift.append(scan_rate_prev)\n",
    "    else : \n",
    "        sell_through_shift.append(None)\n",
    "        scan_through_shift.append(None)\n",
    "        scan_rate_shift.append(None)\n",
    "    \n",
    "    sell_through_prev = row['c_sell_through_avg']\n",
    "    scan_through_prev = row['c_scan_through_avg']\n",
    "    scan_rate_prev = row['c_scan_rate_avg']\n",
    "    grp = row['home_team_abrv']\n",
    "\n",
    "game_feature['c_sell_through_avg_shift'] = sell_through_shift\n",
    "game_feature['c_scan_through_avg_shift'] = scan_through_shift\n",
    "game_feature['c_scan_rate_avg_shift'] = scan_rate_shift  \n",
    "\n",
    "avg_sell_through_fix = game_feature['c_sell_through_avg_shift'].fillna(game_feature.groupby(['home_team_abrv'])['c_sell_through_avg_shift'].transform('mean'))\n",
    "avg_scan_through_fix = game_feature['c_scan_through_avg_shift'].fillna(game_feature.groupby(['home_team_abrv'])['c_scan_through_avg_shift'].transform('mean'))\n",
    "avg_scan_rate_fix = game_feature['c_scan_rate_avg_shift'].fillna(game_feature.groupby(['home_team_abrv'])['c_scan_rate_avg_shift'].transform('mean'))\n",
    "\n",
    "game_feature['c_sell_through_avg_shift_fix']=avg_sell_through_fix\n",
    "game_feature['c_scan_through_avg_shift_fix']=avg_scan_through_fix\n",
    "game_feature['c_scan_rate_avg_shift_fix']=avg_scan_rate_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features list\n",
    "#current win/loss ratio\n",
    "#%neg streak days\n",
    "#%positive streak days\n",
    "#%3+ game streaks\n",
    "#%neg streak days last 10 games\n",
    "#%positive streak days last 10 games\n",
    "#%3+ game streaks last 10 games\n",
    "#day_of_week\n",
    "#home_demand_tier \n",
    "#away_demand_tier\n",
    "#weekend\n",
    "#average scan rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#game_feature.to_csv('game_feature_nba.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#standard score on sell_through, scan_through, scan_rate across season\n",
    "#join back \n",
    "#create z score for each game\n",
    "stdev_sell_through=game_feature.groupby(['home_team_abrv'])['sell_through'].agg(np.std, ddof=0).to_frame()\n",
    "stdev_scan_through=game_feature.groupby(['home_team_abrv'])['scan_through'].agg(np.std, ddof=0).to_frame()\n",
    "stdev_scan_rate=game_feature.groupby(['home_team_abrv'])['scan_rate'].agg(np.std, ddof=0).to_frame()\n",
    "\n",
    "avg_sell_through=game_feature.groupby(['home_team_abrv'])['sell_through'].agg(np.average).to_frame()\n",
    "avg_scan_through=game_feature.groupby(['home_team_abrv'])['scan_through'].agg(np.average).to_frame()\n",
    "avg_scan_rate=game_feature.groupby(['home_team_abrv'])['scan_rate'].agg(np.average).to_frame()\n",
    "\n",
    "stdev_sell_through.rename(columns = {'sell_through':'sell_through_stdev'}, inplace = True)\n",
    "stdev_scan_through.rename(columns = {'scan_through':'scan_through_stdev'}, inplace = True)\n",
    "stdev_scan_rate.rename(columns = {'scan_rate':'scan_rate_stdev'}, inplace = True)\n",
    "\n",
    "avg_sell_through.rename(columns = {'sell_through':'sell_through_avg'}, inplace = True)\n",
    "avg_scan_through.rename(columns = {'scan_through':'scan_through_avg'}, inplace = True)\n",
    "avg_scan_rate.rename(columns = {'scan_rate':'scan_rate_avg'}, inplace = True)\n",
    "\n",
    "game_feature = pd.merge(game_feature, stdev_sell_through,  how='left', on=['home_team_abrv'])\n",
    "game_feature = pd.merge(game_feature, stdev_scan_through,  how='left', on=['home_team_abrv'])\n",
    "game_feature = pd.merge(game_feature, stdev_scan_rate,  how='left', on=['home_team_abrv'])\n",
    "\n",
    "game_feature = pd.merge(game_feature, avg_sell_through,  how='left', on=['home_team_abrv'])\n",
    "game_feature = pd.merge(game_feature, avg_scan_through,  how='left', on=['home_team_abrv'])\n",
    "game_feature = pd.merge(game_feature, avg_scan_rate,  how='left', on=['home_team_abrv'])\n",
    "\n",
    "\n",
    "d = {'sell_through_stdev': ['max']\\\n",
    "     ,'scan_through_stdev': ['max']\\\n",
    "     ,'scan_rate_stdev': ['max']\\\n",
    "     ,'sell_through_avg': ['max']\\\n",
    "     ,'scan_through_avg': ['max']\\\n",
    "     ,'scan_rate_avg': ['max']\\\n",
    "    }\n",
    "\n",
    "rates_meta=game_feature.groupby(['home_team_abrv']).agg(d)\n",
    "\n",
    "sell_through_z = []\n",
    "scan_through_z = []\n",
    "scan_rate_z = []\n",
    "\n",
    "for index, row in game_feature.iterrows():\n",
    "    sell_through_z.append((row['sell_through']-row['sell_through_avg'])/row['sell_through_stdev'])\n",
    "    scan_through_z.append((row['scan_through']-row['scan_through_avg'])/row['scan_through_stdev'])\n",
    "    scan_rate_z.append((row['scan_rate']-row['scan_rate_avg'])/row['scan_rate_stdev'])\n",
    "\n",
    "game_feature['sell_through_std'] = sell_through_z\n",
    "game_feature['scan_through_std'] = scan_through_z\n",
    "game_feature['scan_rate_std'] = scan_rate_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_feature.to_csv('game_feature_nhl.csv')\n",
    "rates_meta.to_csv('rates_meta_nhl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#keep just columns for prediction\n",
    "game_feature_predict=game_feature[[\\\n",
    "'streak',\\\n",
    "'home_team_abrv',\\\n",
    "'game_date',\\\n",
    "'weekend_flag',\\\n",
    "'first_game_flag',\\\n",
    "'group_id',\\\n",
    "'game_id',\\\n",
    "'away_team',\\\n",
    "'away_demand_tier',\\\n",
    "'home_demand_tier',\\\n",
    "'seats_sold',\\\n",
    "'scanned_seats',\\\n",
    "'assumed_capacity',\\\n",
    "'wl_ratio',\\\n",
    "'pct_neg_streak',\\\n",
    "'pct_pos_streak_gt_2_days',\\\n",
    "'pct_c10_neg_streak_days',\\\n",
    "'pct_c10_pos_streak_gt_2_days',\\\n",
    "'Friday',\\\n",
    "'Monday',\\\n",
    "'Saturday',\\\n",
    "'Sunday',\\\n",
    "'Thursday',\\\n",
    "'Tuesday',\\\n",
    "'Wednesday',\\\n",
    "'h_1_a_1',\\\n",
    "'h_1_a_2',\\\n",
    "'h_1_a_3',\\\n",
    "'h_2_a_1',\\\n",
    "'h_2_a_2',\\\n",
    "'h_2_a_3',\\\n",
    "'h_3_a_1',\\\n",
    "'h_3_a_2',\\\n",
    "'h_3_a_3',\\\n",
    "'sell_through',\\\n",
    "'scan_through',\\\n",
    "'scan_rate',\\\n",
    "'c_sell_through_avg_shift_fix',\\\n",
    "'c_scan_through_avg_shift_fix',\\\n",
    "'c_scan_rate_avg_shift_fix',\\\n",
    "'sell_through_avg',\\\n",
    "'scan_through_avg',\\\n",
    "'scan_rate_avg',\\\n",
    "'sell_through_std',\\\n",
    "'scan_through_std',\\\n",
    "'scan_rate_std']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_feature_predict.to_csv('game_feature_predict_nhl.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
