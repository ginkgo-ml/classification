{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T12:21:44.472090Z",
     "start_time": "2019-07-24T12:21:43.282991Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import libraries \n",
    "#psycopg2 creates the conncetions to sql dbs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import sys\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import tweepy\n",
    "\n",
    "#from IPython.core.display import display, HTML\n",
    "#display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user = os.environ['PSQL_USERNAME']\n",
    "postgres_pw = os.environ['PSQL_PASSWORD']\n",
    "postgres_url = os.environ['PSQL_URL']\n",
    "\n",
    "redshift_user = os.environ['REDSHIFT_USERNAME']\n",
    "redshift_pw = os.environ['REDSHIFT_PASSWORD']\n",
    "redshift_url = os.environ['REDSHIFT_URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_consumer_key = os.environ['TWT_CONSUMER_KEY']\n",
    "t_consumer_secret = os.environ['TWT_CONSUMER_SECRET']\n",
    "t_access_token = os.environ['TWT_ACCESS_TOKEN_KEY']\n",
    "t_access_token_secret = os.environ['TWT_ACCESS_TOKEN_SECRET']\n",
    "\n",
    "# authentication of consumer key and secret \n",
    "auth = tweepy.OAuthHandler(t_consumer_key, t_consumer_secret) \n",
    "    \n",
    "# authentication of access token and secret \n",
    "auth.set_access_token(t_access_token, t_access_token_secret) \n",
    "api = tweepy.API(auth) \n",
    "\n",
    "def tweet(txtout):\n",
    "    TARGET_DAY_FORMAT=datetime.today().strftime(\"%c\")\n",
    "    # update the status \n",
    "    api.update_status(\"status | \"+TARGET_DAY_FORMAT+\" \"+txtout) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet(\"Starting Additional Game Features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T18:51:15.528734Z",
     "start_time": "2019-07-23T18:51:15.524801Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this block makes the connection to postgres db (tableau/follower)\n",
    "conn_string = \"host='\"+postgres_url+\"' dbname='experience' user='\"+postgres_user+\"' password='\"+postgres_pw+\"'\"\n",
    "conn = psycopg2.connect(conn_string)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this block makes the connection to redshift (redluma)\n",
    "red_engine = create_engine('postgresql://'+redshift_user+':'+redshift_pw+'@'+redshift_url)\n",
    "conn_red = red_engine.raw_connection()\n",
    "cur = conn_red.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement=\"\"\" \n",
    "    select gr.group_type_id, count(*) as groups\n",
    "    from \"group\" gr\n",
    "    where group_type_id in (1,2,3,4,5,8,9,15,41)\n",
    "    --where group_type_id in (3)\n",
    "    group by 1;\n",
    "    \"\"\"  \n",
    "group_types = pd.read_sql(statement, conn)\n",
    "group_types_list = group_types['group_type_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy = pd.read_sql(\"select distinct * from reporting.away_team_lookup_fuzzy;\", conn_red)\n",
    "\n",
    "column_indices = [1,3,4]\n",
    "new_names_fuzzy = ['fixed_name','away_group_id','match_confidence']\n",
    "old_names = fuzzy.columns[column_indices]\n",
    "\n",
    "fuzzy_away=fuzzy.rename(columns=dict(zip(old_names, new_names_fuzzy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue = pd.read_sql(\"select distinct * from venue;\", conn)\n",
    "\n",
    "column_indices = [2,4,5,8,9]\n",
    "new_names_home = ['home_group_id','home_lat','home_long','home_avg_attendance','home_max_attendance']\n",
    "new_names_away = ['away_group_id','away_lat','away_long','away_avg_attendance','away_max_attendance']\n",
    "old_names = venue.columns[column_indices]\n",
    "\n",
    "venue_away=venue.rename(columns=dict(zip(old_names, new_names_away)))\n",
    "venue_home=venue.rename(columns=dict(zip(old_names, new_names_home)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/core/frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "all_matches = pd.DataFrame(columns=[\\\n",
    "        'event_id',\\\n",
    "        'group_type_id',\\\n",
    "        'away_team',\\\n",
    "        'home_team_id',\\\n",
    "        'home_group_id',\\\n",
    "        'home_lat',\\\n",
    "        'home_long',\\\n",
    "        'home_venue_name',\\\n",
    "        'home_avg_attendance',\\\n",
    "        'home_max_attendance',\\\n",
    "        'fixed_name',\\\n",
    "        'away_group_id',\\\n",
    "        'match_confidence',\\\n",
    "        'away_lat',\\\n",
    "        'away_long',\\\n",
    "        'away_avg_attendance'])\n",
    "\n",
    "for gtype in group_types_list:\n",
    "    statement=\"\"\" \n",
    "    select distinct g.id, gr.group_type_id, g.away_team, g.home_team_id\n",
    "    from game g\n",
    "    left join \"group\" gr on g.home_team_id=gr.id\n",
    "    where (g.game_start_time)>= '2017-01-01' and group_type_id={};\n",
    "    \"\"\".format(str(gtype))  \n",
    "    games = pd.read_sql(statement, conn)\n",
    "\n",
    "    home_team_stats=pd.merge(games, venue_home, left_on='home_team_id',right_on='home_group_id', how='left')\n",
    "    away_team_match=pd.merge(home_team_stats, fuzzy_away, on=['away_team','group_type_id'], how='inner')  \n",
    "    away_team_stats=pd.merge(away_team_match, venue_away, left_on='away_group_id',right_on='away_group_id', how='left')  \n",
    "    \n",
    "    keep = away_team_stats[[\\\n",
    "        'id_x',\\\n",
    "        'group_type_id',\\\n",
    "        'away_team',\\\n",
    "        'home_team_id',\\\n",
    "        'home_group_id',\\\n",
    "        'home_lat',\\\n",
    "        'home_long',\\\n",
    "        'name_x',\\\n",
    "        'home_avg_attendance',\\\n",
    "        'home_max_attendance',\\\n",
    "        'fixed_name',\\\n",
    "        'away_group_id',\\\n",
    "        'match_confidence',\\\n",
    "        'away_lat',\\\n",
    "        'away_long',\\\n",
    "        'away_avg_attendance',\\\n",
    "        'away_max_attendance']]\n",
    "\n",
    "    column_indices = [0,7]\n",
    "    new_names_stats = ['event_id','home_venue_name']\n",
    "    old_names = keep.columns[column_indices]\n",
    "\n",
    "    keep_rename=keep.rename(columns=dict(zip(old_names, new_names_stats)))\n",
    "    \n",
    "    all_matches=all_matches.append(keep_rename, ignore_index=True)  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "import geopy.distance\n",
    "distances=[]\n",
    "\n",
    "for index, row in all_matches.iterrows():\n",
    "    away_lat=row['away_lat']\n",
    "    away_long=row['away_long']\n",
    "    coords_1 = (away_lat, away_long)\n",
    "    home_lat=row['home_lat']\n",
    "    home_long=row['home_long']\n",
    "    coords_2 = (home_lat, home_long)\n",
    "    if away_lat>0 and home_lat>0 and away_long<0 and home_long<0:\n",
    "        distances.append(geopy.distance.distance(coords_1, coords_2).miles)\n",
    "    else:\n",
    "         distances.append(None)\n",
    "            \n",
    "all_matches['distance']=distances    \n",
    "all_matches_with_distance=all_matches.dropna(subset=['distance'])\n",
    "all_matches_with_distance.drop(all_matches_with_distance[all_matches_with_distance.distance < 5].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_stdv=all_matches_with_distance.groupby(['group_type_id'])['distance'].agg(np.std, ddof=0).to_frame()\n",
    "all_matches_avg=all_matches_with_distance.groupby(['group_type_id'])['distance'].agg(np.average).to_frame()\n",
    "\n",
    "all_matches_stdv.rename(columns = {'distance':'distance_stdev'}, inplace = True)\n",
    "all_matches_avg.rename(columns = {'distance':'distance_avg'}, inplace = True)\n",
    "\n",
    "all_matches = pd.merge(all_matches, all_matches_stdv,  how='left', on=['group_type_id'])\n",
    "all_matches = pd.merge(all_matches, all_matches_avg,  how='left', on=['group_type_id'])\n",
    "\n",
    "distance_z = []\n",
    "\n",
    "for index, row in all_matches.iterrows():\n",
    "    distance_z.append((row['distance']-row['distance_avg'])/row['distance_stdev'])\n",
    "\n",
    "all_matches['distance_z'] = distance_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches['home_avg_attendance'] = all_matches['home_avg_attendance'].astype(float)\n",
    "all_matches['home_max_attendance'] = all_matches['home_max_attendance'].astype(float)\n",
    "\n",
    "all_matches_with_home_max_attendance=all_matches.dropna(subset=['home_max_attendance'])\n",
    "all_matches_with_away_max_attendance=all_matches.dropna(subset=['away_max_attendance'])\n",
    "all_matches_with_home_avg_attendance=all_matches.dropna(subset=['home_avg_attendance'])\n",
    "all_matches_with_away_avg_attendance=all_matches.dropna(subset=['away_avg_attendance'])\n",
    "\n",
    "all_matches_with_home_max_attendance.drop(all_matches_with_home_max_attendance[all_matches_with_home_max_attendance.home_max_attendance < 5].index, inplace=True)\n",
    "all_matches_with_away_max_attendance.drop(all_matches_with_away_max_attendance[all_matches_with_away_max_attendance.away_max_attendance < 5].index, inplace=True)\n",
    "all_matches_with_home_avg_attendance.drop(all_matches_with_home_avg_attendance[all_matches_with_home_avg_attendance.home_avg_attendance < 5].index, inplace=True)\n",
    "all_matches_with_away_avg_attendance.drop(all_matches_with_away_avg_attendance[all_matches_with_away_avg_attendance.away_avg_attendance < 5].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_matches_stdv=all_matches_with_home_max_attendance.groupby(['group_type_id'])['home_max_attendance'].agg(np.std, ddof=0).to_frame()\n",
    "all_matches_avg=all_matches_with_home_max_attendance.groupby(['group_type_id'])['home_max_attendance'].agg(np.average).to_frame()\n",
    "\n",
    "all_matches_stdv.rename(columns = {'home_max_attendance':'home_max_attendance_stdev'}, inplace = True)\n",
    "all_matches_avg.rename(columns = {'home_max_attendance':'home_max_attendance_avg'}, inplace = True)\n",
    "\n",
    "all_matches = pd.merge(all_matches, all_matches_stdv,  how='left', on=['group_type_id'])\n",
    "all_matches = pd.merge(all_matches, all_matches_avg,  how='left', on=['group_type_id'])\n",
    "\n",
    "home_max_attendance_z = []\n",
    "\n",
    "for index, row in all_matches.iterrows():\n",
    "    home_max_attendance_z.append((row['home_max_attendance']-row['home_max_attendance_avg'])/(row['home_max_attendance_stdev']+1))\n",
    "\n",
    "all_matches['home_max_attendance_z'] = home_max_attendance_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_stdv=all_matches_with_home_avg_attendance.groupby(['group_type_id'])['home_avg_attendance'].agg(np.std, ddof=0).to_frame()\n",
    "all_matches_avg=all_matches_with_home_avg_attendance.groupby(['group_type_id'])['home_avg_attendance'].agg(np.average).to_frame()\n",
    "\n",
    "all_matches_stdv.rename(columns = {'home_avg_attendance':'home_avg_attendance_stdev'}, inplace = True)\n",
    "all_matches_avg.rename(columns = {'home_avg_attendance':'home_avg_attendance_avg'}, inplace = True)\n",
    "\n",
    "all_matches = pd.merge(all_matches, all_matches_stdv,  how='left', on=['group_type_id'])\n",
    "all_matches = pd.merge(all_matches, all_matches_avg,  how='left', on=['group_type_id'])\n",
    "\n",
    "home_avg_attendance_z = []\n",
    "\n",
    "for index, row in all_matches.iterrows():\n",
    "    home_avg_attendance_z.append((row['home_avg_attendance']-row['home_avg_attendance_avg'])/(row['home_avg_attendance_stdev']+1))\n",
    "\n",
    "all_matches['home_avg_attendance_z'] = home_avg_attendance_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_stdv=all_matches_with_away_max_attendance.groupby(['group_type_id'])['away_max_attendance'].agg(np.std, ddof=0).to_frame()\n",
    "all_matches_avg=all_matches_with_away_max_attendance.groupby(['group_type_id'])['away_max_attendance'].agg(np.average).to_frame()\n",
    "\n",
    "all_matches_stdv.rename(columns = {'away_max_attendance':'away_max_attendance_stdev'}, inplace = True)\n",
    "all_matches_avg.rename(columns = {'away_max_attendance':'away_max_attendance_avg'}, inplace = True)\n",
    "\n",
    "all_matches = pd.merge(all_matches, all_matches_stdv,  how='left', on=['group_type_id'])\n",
    "all_matches = pd.merge(all_matches, all_matches_avg,  how='left', on=['group_type_id'])\n",
    "\n",
    "away_max_attendance_z = []\n",
    "\n",
    "for index, row in all_matches.iterrows():\n",
    "    away_max_attendance_z.append((row['away_max_attendance']-row['away_max_attendance_avg'])/(row['away_max_attendance_stdev']+1))\n",
    "\n",
    "all_matches['away_max_attendance_z'] = away_max_attendance_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches_stdv=all_matches_with_away_avg_attendance.groupby(['group_type_id'])['away_avg_attendance'].agg(np.std, ddof=0).to_frame()\n",
    "all_matches_avg=all_matches_with_away_avg_attendance.groupby(['group_type_id'])['away_avg_attendance'].agg(np.average).to_frame()\n",
    "\n",
    "all_matches_stdv.rename(columns = {'away_avg_attendance':'away_avg_attendance_stdev'}, inplace = True)\n",
    "all_matches_avg.rename(columns = {'away_avg_attendance':'away_avg_attendance_avg'}, inplace = True)\n",
    "\n",
    "all_matches = pd.merge(all_matches, all_matches_stdv,  how='left', on=['group_type_id'])\n",
    "all_matches = pd.merge(all_matches, all_matches_avg,  how='left', on=['group_type_id'])\n",
    "\n",
    "away_avg_attendance_z = []\n",
    "\n",
    "for index, row in all_matches.iterrows():\n",
    "    away_avg_attendance_z.append((row['away_avg_attendance']-row['away_avg_attendance_avg'])/(row['away_avg_attendance_stdev']+1))\n",
    "\n",
    "all_matches['away_avg_attendance_z'] = away_avg_attendance_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_additional_features=all_matches\n",
    "events_additional_features.to_csv(\"assets/event_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet(\"Additional Game Features Finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
